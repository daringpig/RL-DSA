# Deep-Reinforcement-Learning-for-Dynamic-Spectrum-Access

## Dependencies


1. python [link](https://www.python.org)
2. matplotlib [link](https://matplotlib.org/)
3. tensorflow > 1.0 [link](https://www.tensorflow.org/)
4. numpy [link](https://www.numpy.org/)
5. jupyter [link](http://jupyter.org/)

We recommend to install with [Anaconda](https://anaconda.org/anaconda/python) 


### To train the DQN ,run on terminal
```bash
git clone https://github.com/shkrwnd/Deep-Reinforcement-Learning-for-Dynamic-Spectrum-Access.git
cd Deep-Reinforcement-Learning-for-Dynamic-Spectrum-Access
python train.py
```

To understand the code , I have provided jupyter notebooks:
1. How to use environment.ipynb
2. How to generate states.ipynb
3. How_to_create_cluster.ipynb

To run notebook,run on terminal
```bash
jupyter notebook
```
Default browser will open ipynb files. Run each command one by one


This work is an inspiration from the paper
```
O. Naparstek and K. Cohen, “Deep multi-user reinforcement learning for dynamic spectrum access in multichannel wireless
networks,” to appear in Proc. of the IEEE Global Communications Conference (GLOBECOM), Dec. 2017
```




# RL-DSA
# RL-DSA
